---
layout: post
title: "Generative Adversarial Network(s)"
description: ""
redirect_from:
  - /2022/05/12/
date: 22-05-12

---

### What are GAN(s) ?
GAN is a neural network which helps in generating content. The first application of GAN was to generate images, hence in the following blog, we'll talk in that language. However, GAN(s) are not limited to generating only images. 
> The "G" in GAN stands for "Generative".

In a GAN, there are 2 different neural networks which are playing a [minimax](2022-05-12-minimax.md) game with each other. One of the network is known as a Generator, denoted by G(z); the other is known as the Differentiator, denoted by D(x). 
> The "A" in GAN stands for "Adversarial", denoting the *adversarial* relationship between the Generator and the Discriminator.

You might have observed the different types of inputs provided to G and D. The input to G is from a fixed sample space taken from a [standard normal distribution](2022-05-12-standard-normal-distribution-rabbit-hole.md). This is denoted by a vector space *z*. The input to D is of two types:
1. The real data that the network is being trained on. This is denoted by *x*.
2. The output of Generator - more on this later.  

**Technical defintion:** GAN is a type of network that tries to understand (learn) the [distribution](2022-05-12-standard-normal-distribution-rabbit-hole.md) of the input data. Once learned the distribution of input data, the network should be able to generate new data having the same distribution.

### Building blocks of GAN
As explained above, GAN is a combination of two networks - Generator and Discriminator. The aim of the discriminator is to tell whether this data is fake or real. In other words, the discriminator is striving to get better at discriminating at each iteration. The discriminator network can also be thought of as a binary classifier. The building blocks of a discriminator are strided convolutional layers, ReLU activations, and Batch Norm layers.<br>
The aim of the generator is to generate a data so good that the generator is unable to identify whether the data is real or fake. In other words, the generator is trying to become a better *counterfeiter* with every iteration. The building blocks of a generator are transpose convolutional layer(s), leaky ReLU activations, and Batch Norm layers.

### The Loss Function
The Loss expression for a GAN is given below:
![GAN Loss Expression](/assets/imgs/gan_loss_expression.png)

---

Q. Why 1 - D(G(z)) ? 
	- That's because this transformation points the desires of the discriminator and Generator in consistent directions between the two terms in the equation. 
	- The discriminator wants to maximise the entire function, the generator wants to minimise the entire function.



- first term is the expectation of the log of the output of the discriminator when the input is from real data distribution.



---
**References::**
1. [A Friendly Introduction to Generative Adversarial Networks (GANs)](https://www.youtube.com/watch?v=8L11aMN5KY8)
2. [Understand the Math and Theory of GANs in ~ 10 minutes](https://youtu.be/J1aG12dLo4I)
3. [Pytorch Tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#implementation)