---
layout: post
title: "Generative Adversarial Network(s)"
description: ""
redirect_from:
  - /2022/05/12/
date: 22-05-12

---

### What are GAN(s) ?
GAN is a neural network which helps in generating content. The first application of GAN was to generate an image, hence in the following literature, we'll talk in that language. However, GAN(s) are not limited to generating only images. 
> The "G" in GAN stands for "Generative".

In a GAN, there are 2 different neural networks which are playing a [minimax](2022-05-12-minimax.md) game with each other. One of the network is known as a Generator, denoted by G(z); the other is known as the Differentiator, denoted by D(x). 
> The "A" in GAN stands for "Adversarial", denoting the *adversarial* relationship between the Generator and the Discriminator.

You might have observed the difference between the input to G and the input to D. The input to G is from a fixed sample space taken from a [standard normal distribution](2022-05-12-standard-normal-distribution-rabbit-hole.md). This is denoted by a vector space *z*. The input to D is of two types:
1. The real data that the network is being trained on. This is denoted by *x*.
2. The output of Generator - more on this later.  

**Technical defintion:** GAN is a type of netowk that tries to understand (learn) the [distribution]((2022-05-12-standard-normal-distribution-rabbit-hole.md)) of the input data. Once learned the distribution of input data, the network should be able to generate new data having the same distribution.

### Working of a GAN
As explaiend above, GAN is a combination of two networks - Generator and Discriminator. First of all, we pass the input to the generator, forcing it to generate an output having the dimensions of the actual data. Next, this generated output is fed to the discriminator. The aim of the discriminator is to tell whether this data is fake or real. On the other hand, the aim of the generator is to generate a data so good that the generator is unable to identify whether the data is real or fake. In this particular case, the generated output is denoted by G(z), while the output of the discriminator is denoted by D(G(z)). After the generator has given it's output, the loss is calculated. However, optim.step is not called yet. <br>
In the next step, the discriminator is fed real data. The output is denoted by G(x). Note that in this step, the Generator is not used. The loss is calculated again. The two losses are clubbed and the optim.step function is called. 

### The Loss Function
The Loss expression for a GAN is given below:
![GAN Loss Expression](/assets/imgs/gan_loss_expression.png)

---

Q. Why 1 - D(G(z)) ? 
	- That's because this transformation points the desires of the discriminator and Generator in consistent directions between the two terms in the equation. 
	- The discriminator wants to maximise the entire function, the generator wants to minimise the entire function.



- first term is the expectation of the log of the output of the discriminator when the input is from real data distribution.



---
**References::**
1. [A Friendly Introduction to Generative Adversarial Networks (GANs)](https://www.youtube.com/watch?v=8L11aMN5KY8)
2. [Understand the Math and Theory of GANs in ~ 10 minutes](https://youtu.be/J1aG12dLo4I)
3. [Pytorch Tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#implementation)